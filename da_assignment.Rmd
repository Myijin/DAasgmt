---
title: "Data Analyst Take-Home Assignment"
author: "Yijing Cai"
output: pdf_document
geometry: margin=0.65in
---
**Libraries or packages used**: ggplot2, gridExtra for plot, caret for evaluate models.

**Data Description:**

As the output below shows, the copackager table has 1200 observations and 10 columns, which means 1200 packaging jobs. Among them, 600 jobs' customer are Procter & Gamble and 600 jobs' customer are Unilever. 866 jobs are On-Time In-Full (OTIF) while 334 jobs are not OTIF.

Dimensions of data and descriptions of columns:
```{r, echo=FALSE}
copackager <- read.csv("copackager_table.csv")
str(copackager,width=86,strict.width="cut")
```
Counts by OTIF or job customer:
```{r, echo=FALSE}
copackager[,c(2,3,4,5,8)] <- sapply(copackager[,c(2,3,4,5,8)], 
                                    function(x) strptime(x, "%y-%m-%d %H:%M"))
copackager$OTIF.factor <- factor(copackager$OTIF)
summary(copackager[,c(11,10)])
```
**Cleaning data**:

1) I checked for missing value and there is none.

2) The values in columns where dates and times are stored are converted to date/time objects for calculation purpose. The values in OTIF column are converted from integer to factors to be treated as categorical variable.

2) Erroneous values were corrected by removing all the observations with purchase order received date later than materials availability date, or materials availability date later than production started date, or production started date later or equal to production completed date, or production completed date later or equal to shipment shipped date.  After cleaning, there are 1101 observations left.

Dimensions of cleaned data:
```{r, message=FALSE, echo=FALSE, results="hide"}
sapply(copackager, function(x) sum(is.na(x)))
cleanCopackager <- copackager[
  which(copackager$purchase.order.received.date<=copackager$materials.availablity.date 
        & copackager$materials.availablity.date<=copackager$production.started.date
        & copackager$production.completed.date>copackager$production.started.date
        & copackager$shipment.shipped.date>copackager$production.completed.date) , ]
```
```{r, echo=FALSE}
dim(cleanCopackager)
```
Counts by OTIF or job customer for cleaned data:
```{r, echo=FALSE}
summary(cleanCopackager[,c(11,10)])
```

\newpage

\vspace*{0.22in}

### Q1: What is the average shift length? 
\vspace*{-0.12in}

Histogram for Shift Time:
```{r, echo=FALSE, fig.align='center', fig.width=4.6, fig.height=3.5}
library(ggplot2)
cleanCopackager$shift.time <- as.numeric(
  cleanCopackager$production.completed.date - cleanCopackager$production.started.date, 
  units="hours")
qplot(cleanCopackager$shift.time,
      geom="histogram",
      xlab = "shift time",
      binwidth=1,
      fill=I("grey"), 
      col=I("black"))
```
Code output for mean shift time:
```{r, echo=FALSE}
print(mean(cleanCopackager$shift.time))
```
Answer: 9.866409 $\approx$ 10hrs

\newpage

### Q2.1: What is the change in probability of OTIF 3 days after receiving the PO vs 4 days?

\vspace*{-0.12in}
**Assumption**: Based on description file, we can assume that the job is always completed in full (the packaged quantity is equal to that outlined in the PO).

Model for predicting OTIF based on the time from receiving the PO to shipment shipped:

\vspace*{-0.12in}
```{r, echo=FALSE}
cleanCopackager$cycle.time <- as.numeric(
  cleanCopackager$shipment.shipped.date-cleanCopackager$purchase.order.received.date, 
  units="days")
# prob_3 = mean(subset(cleanCopackager, cleanCopackager$cycle.time <=3 
#                      & cleanCopackager$cycle.time > 2)$OTIF, na.rm = TRUE)
# prob_4 = mean(subset(cleanCopackager, cleanCopackager$cycle.time <=4 
#                      & cleanCopackager$cycle.time > 3)$OTIF, na.rm = TRUE)
# print(sprintf('%.1f%%', (prob_3-prob_4)*100))
model <- glm(OTIF.factor~ cycle.time, data=cleanCopackager, family=binomial(logit))  
print(summary(model))
```
Residual deviance for the model with predictors is samller than deviance for the null model. Likelihood ratio test p-value less than 0.001 tells us that our model as a whole fits significantly better than an empty model.

\vspace*{-0.1in}
```{r, echo=FALSE}
with(model, null.deviance - deviance)
pval <- with(model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
paste0("p-value:", pval)
```
```{r, fig.align='center', fig.width=4.9, fig.height=3.6, echo=FALSE, message=FALSE, warning=FALSE}
model.df <- data.frame(cycle.time = seq(0, 20, 1))
model.df$otif <- predict(model, newdata=model.df, type="response")
# Plot the modeled probability values
ggplot(model.df, aes(x=cycle.time, y=otif)) + geom_line() + 
  xlab("Days") +
  ylab("Probability of OTIF") + 
  geom_segment(aes(x =-Inf, xend =3,
                   y =0.9607, yend =0.9607),linetype = "dashed") + 
  geom_segment(aes(x =-Inf, xend =4,
                   y =0.9393, yend =0.9393),linetype = "dashed") +
  geom_segment(aes(x =4, xend =4,
                   y =-Inf, yend =0.9393),linetype = "dashed") + 
  geom_segment(aes(x =3, xend =3,
                   y =-Inf, yend =0.9607),linetype = "dashed") + 
  annotate(geom="text", x=4.8, y=0.9807, label="(3, 0.961)", color="grey30") + 
  annotate(geom="text", x=6.3, y=0.9393, label="(4, 0.939)", color="grey30")
```
Code output for probability of OTIF 3 days after minus probability of 4 days after:

\vspace*{-0.1in}
```{r, echo=FALSE}
# predict.glm(model, newdata=data.frame(cycle.time=3), type="response")
# predict.glm(model, newdata=data.frame(cycle.time=4), type="response")
print(predict.glm(model, newdata=data.frame(cycle.time=3), type="response")[[1]]-
        predict.glm(model, newdata=data.frame(cycle.time=4), type="response")[[1]])
```

Answer: 2%

\newpage

### Q2.2: How many days can the supplier afford to wait after receiving the PO to start production if they hope to be OTIF?
\vspace*{-0.12in}
**Assumption**: The effects of other factors like the time from starting production to shipment shipped, or how long is the time from receiving PO to due date, are not considered.

\vspace*{-0.1in}
```{r, echo=FALSE}
cleanCopackager$wait.toproduct <- as.numeric(
  cleanCopackager$production.started.date-cleanCopackager$purchase.order.received.date, 
  units="days")
model <- glm(OTIF.factor~ wait.toproduct, data=cleanCopackager, family=binomial(logit))  
summary(model)
```
Residual deviance for the model with predictors is samller than deviance for the null model. Likelihood ratio test p-value less than 0.001 tells us that our model as a whole fits significantly better than an empty model.

\vspace*{-0.1in}
```{r, echo=FALSE}
with(model, null.deviance - deviance)
pval <- with(model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
paste0("p-value:", pval)
```
I built the above model to predict OTIF based on the time packagers wait after receiving the PO to start production. When the input is 6 days, the model predicts true, which means jobs are more likely to be OTIF.

\vspace*{-0.1in}
```{r, echo=FALSE}
(predict.glm(model, newdata=data.frame(wait.toproduct=6), type="response")>0.5)[[1]]
# print(predict.glm(model, newdata=data.frame(wait.toproduct=6), type="response"))
```
When the input is 7 days, the model predicts false, which means jobs are more likely to be not on time.

\vspace*{-0.1in}
```{r, echo=FALSE}
(predict.glm(model, newdata=data.frame(wait.toproduct=7), type="response")>0.5)[[1]]
# print(predict.glm(model, newdata=data.frame(wait.toproduct=7), type="response"))
```

\vspace*{-0.16in}
```{r, fig.align='center', fig.width=4.9, fig.height=3.6, echo=FALSE, message=FALSE, warning=FALSE}
model.df <- data.frame(wait.toproduct = seq(0, 15, 0.5))
model.df$otif <- predict(model, newdata=model.df, type="response")
# Plot the modeled probability values
ggplot(model.df, aes(x=wait.toproduct, y=otif)) + geom_line() + 
  xlab("Days") +
  ylab("Probability of OTIF") + 
  geom_segment(aes(x =-Inf, xend =6,
                   y =0.6367677, yend =0.6367677),linetype = "dashed") + 
  geom_segment(aes(x =-Inf, xend =7,
                   y =0.46691464, yend =0.46691464),linetype = "dashed") +
  geom_segment(aes(x =7, xend =7,
                   y =-Inf, yend =0.46691464),linetype = "dashed") + 
  geom_segment(aes(x =6, xend =6,
                   y =-Inf, yend =0.6367677),linetype = "dashed") + 
  annotate(geom="text", x=7.5, y=0.656, label="(6, 0.64)", color="grey30") + 
  annotate(geom="text", x=8.5, y=0.487, label="(7, 0.47)", color="grey30")
```

\vspace*{-0.25in}
Answer: 6 days or less

\newpage

Additional evaluation for the two models in Q2:

When predictor is the time from receiving the PO to start production, here are some statistics for the model.
```{r, echo=FALSE, message=FALSE}
library(caret)
set.seed(88)
sample <- sample.int(n = nrow(cleanCopackager), size = floor(.8*nrow(cleanCopackager)), replace = F)
train <- cleanCopackager[sample, ]
test  <- cleanCopackager[-sample, ]
model1 <- glm(OTIF.factor~ wait.toproduct, data=train, family=binomial(logit)) 
fitted.results <- predict(model1, newdata=test, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
accuracy <- 1-mean(fitted.results != test$OTIF.factor)
results <- confusionMatrix(data=fitted.results, reference=test$OTIF.factor)
print(results)
# pr <- prediction(fitted.results, test$OTIF.factor)
# prf <- performance(pr, measure = "tpr", x.measure = "fpr")
# plot(prf)
```

When predictor is the time from receiving the PO to shipment shipped, here are some statistics for the model.
```{r, echo=FALSE, message=FALSE}
model2 <- glm(OTIF.factor~ cycle.time, data=cleanCopackager, family=binomial(logit))  
fitted.results <- predict(model2, newdata=test, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
accuracy <- 1-mean(fitted.results != test$OTIF.factor)
results <- confusionMatrix(data=fitted.results, reference=test$OTIF.factor)
print(results)
# pr <- prediction(fitted.results, test$OTIF.factor)
# prf <- performance(pr, measure = "tpr", x.measure = "fpr")
# plot(prf)
```

\newpage

###Q3: Is the difference in quantity produced between P&G and Unilever statistically significant?
\vspace*{-0.12in}

I have converted the quantity to number of eaches based on customer_unit_of_measure_conversions.csv. From histogram and Shapiro-Wilk test, we can learn that the distribution of data is not normal. 

```{r, message=FALSE, echo=FALSE}
cleanCopackager$converse.rate <- 
  ifelse(cleanCopackager$unit.of.measure == "cases" 
         & cleanCopackager$customer == "Procter & Gamble", 2,
         ifelse(cleanCopackager$unit.of.measure == "cases" 
                & cleanCopackager$customer == "Unilever", 3,
                ifelse(cleanCopackager$unit.of.measure == "pallets" 
                       & cleanCopackager$customer == "Procter & Gamble", 12,
                       ifelse(cleanCopackager$unit.of.measure == "pallets" 
                              & cleanCopackager$customer == "Unilever", 15,1
                              ))))
cleanCopackager$converse.quantity <- cleanCopackager$converse.rate*cleanCopackager$quantity.produced
```
```{r, message=FALSE, echo=FALSE, fig.align='center', fig.width=6.6, fig.height=2.9}
q.pg <- subset(cleanCopackager, cleanCopackager$customer=="Procter & Gamble")$converse.quantity
q.unilever <- subset(cleanCopackager, cleanCopackager$customer=="Unilever")$converse.quantity
require(gridExtra)
plot1 <- qplot(q.pg,
      geom="histogram",
      xlab = "conversed quantity",
      binwidth=50,
      main="Quantity produced by P&G",
      fill=I("grey"), 
      col=I("black"))
plot2 <- qplot(q.unilever,
      geom="histogram",
      xlab = "conversed quantity",
      binwidth=70,
      main="Quantity produced by Unilever",
      fill=I("grey"), 
      col=I("black"))
grid.arrange(plot1, plot2, ncol=2)
```

\vspace*{-0.26in}
```{r, echo=FALSE}
shapiro.test(q.pg)
# print(t.test(q.pg, q.unilever))
```

\vspace*{-0.12in}
```{r, echo=FALSE}
shapiro.test(q.unilever)
```
Wilcoxon rank-sum test (also called Mannâ€“Whitney U test or Mann-Whitney-Wilcoxon Test) is conducted and it shows that the difference is statistically significant since p-value is very small. Wilcoxon rank-sum test results:

\vspace*{-0.12in}
```{r, echo=FALSE}
wilcox.test(converse.quantity ~ customer, data=cleanCopackager) 
```

Boxplot for quantities produced by P&G and Unilever:

```{r, fig.align='center', fig.width=4.1, fig.height=3.1, echo=FALSE, message=FALSE, warning=FALSE}
plot.data <- data.frame(pg=append(q.pg, rep(NA, 7)), Unilever=q.unilever)
ggplot(stack(plot.data), aes(x = ind, y = values, fill=ind)) + 
  theme(legend.position="none") + xlab("customer") + ylab("quantity") +
  scale_x_discrete(labels=c("pg" = "P&G", "Unilever" = "Unilever")) +
  geom_boxplot()
```

\vspace*{-0.22in}
Answer: Yes

\newpage

### Q4: Assuming everything else is constant, what is the probability of hitting OTIF if the customer was P&G?
\vspace*{-0.12in}
Code output for probability of hitting OTIF if the customer was P&G:
```{r, echo=FALSE}
print(sprintf('%.1f%%', mean(subset(
  cleanCopackager, cleanCopackager$customer=="Procter & Gamble")$OTIF)*100))
```
Pie chart for Procter & Gamble:
```{r, fig.align='center', echo=FALSE}
df <- as.data.frame(table(subset(cleanCopackager, cleanCopackager$customer=="Procter & Gamble")$OTIF))
pct <- round(df$Freq/sum(df$Freq)*100)
lbls <- paste(c("Not OTIF", "OTIF"), pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(df$Freq, labels = lbls, cex=0.75)
```
Pie chart for Unilever:
```{r, fig.align='center', echo=FALSE}
df <- as.data.frame(table(subset(cleanCopackager, cleanCopackager$customer=="Unilever")$OTIF))
pct <- round(df$Freq/sum(df$Freq)*100)
lbls <- paste(c("Not OTIF", "OTIF"), pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(df$Freq, labels = lbls, cex=0.75)
```

Answer: 69%